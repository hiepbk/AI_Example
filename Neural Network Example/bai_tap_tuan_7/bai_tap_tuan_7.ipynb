{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mạng nơ-ron 1 lớp ẩn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Thư viện\n",
    "\n",
    "Import những thư viện cần thiết "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Package imports\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Mô hình mạng\n",
    "\n",
    "**Mô hình**:\n",
    "<img src=\"images/classification_kiank.png\" style=\"width:600px;height:300px;\">\n",
    "\n",
    "**Các công thức liên quan**:\n",
    "\n",
    "Với mỗi ví dụ $x^{(i)}$:\n",
    "$$z^{[1] (i)} =  W^{[1]} x^{(i)} + b^{[1]}$$ \n",
    "$$a^{[1] (i)} = \\tanh(z^{[1] (i)})$$\n",
    "$$z^{[2] (i)} = W^{[2]} a^{[1] (i)} + b^{[2]}$$\n",
    "$$\\hat{y}^{(i)} = a^{[2] (i)} = \\sigma(z^{ [2] (i)})$$\n",
    "$$y^{(i)}_{prediction} = \\begin{cases} 1 & \\mbox{if } a^{[2](i)} > 0.5 \\\\ 0 & \\mbox{otherwise } \\end{cases}$$\n",
    "\n",
    "Hàm chi phí $J$: \n",
    "$$J = - \\frac{1}{m} \\sum\\limits_{i = 0}^{m} \\large\\left(\\small y^{(i)}\\log\\left(a^{[2] (i)}\\right) + (1-y^{(i)})\\log\\left(1- a^{[2] (i)}\\right)  \\large  \\right)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 - Hàm kích hoạt\n",
    "- Sigmoid:\n",
    "$$sigmoid(x) = \\frac{1}{1+e^{-x}}$$\n",
    "- Relu\n",
    "$$relu(x) = max(x, 0)$$\n",
    "- Tanh\n",
    "$$tanh(x)=\\frac{e^{x} - e^{-x}}{e^{x} + e^{-x}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: activation\n",
    "def activation(x, name='sigmoid'):\n",
    "    \"\"\"\n",
    "    Compute the activation function of x\n",
    "\n",
    "    Arguments:\n",
    "        x    -- A scalar or numpy array of any size\n",
    "        name -- type of activation: ReLU, sigmoid (default), tanh\n",
    "\n",
    "    Return:\n",
    "        s -- activation(x)\n",
    "    \"\"\"\n",
    "    \n",
    "    ### START CODE HERE ### \n",
    "    \n",
    "    ### END CODE HERE ###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 - Khởi tạo tham số"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: initialize_parameters\n",
    "\n",
    "def initialize_parameters(n_x, n_h, n_y):\n",
    "    \"\"\"\n",
    "    Argument:\n",
    "        n_x -- size of the input layer\n",
    "        n_h -- size of the hidden layer\n",
    "        n_y -- size of the output layer\n",
    "    \n",
    "    Returns:\n",
    "        parameters -- python dictionary containing:\n",
    "            W1 -- weight matrix of shape (n_h, n_x)\n",
    "            b1 -- bias vector of shape (n_h, 1)\n",
    "            W2 -- weight matrix of shape (n_y, n_h)\n",
    "            b2 -- bias vector of shape (n_y, 1)\n",
    "    \"\"\"\n",
    "    np.random.seed(2)\n",
    "    \n",
    "    ### START CODE HERE ### \n",
    "    \n",
    "    ### END CODE HERE ###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 - Lan truyền xuôi\n",
    "Công thức lan truyền xuôi: Với ví dụ $x^{(i)}$:\n",
    "$$z^{[1] (i)} =  W^{[1]} x^{(i)} + b^{[1]}$$ \n",
    "$$a^{[1] (i)} = \\tanh(z^{[1] (i)})$$\n",
    "$$z^{[2] (i)} = W^{[2]} a^{[1] (i)} + b^{[2]}$$\n",
    "$$\\hat{y}^{(i)} = a^{[2] (i)} = \\sigma(z^{ [2] (i)})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: forward_propagation\n",
    "\n",
    "def forward_propagation(X, parameters):\n",
    "    \"\"\"\n",
    "    Argument:\n",
    "        X -- input data of size (n_x, m)\n",
    "        parameters -- python dictionary containing your parameters (output of initialization function)\n",
    "    \n",
    "    Returns:\n",
    "        A2 -- The sigmoid output of the second activation\n",
    "        cache -- a dictionary containing \"Z1\", \"A1\", \"Z2\" and \"A2\"\n",
    "    \"\"\"\n",
    "    \n",
    "    ### START CODE HERE ### \n",
    "    \n",
    "    ### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 - Hàm chi phí\n",
    "Công thức hàm chi phí $J$: \n",
    "$$J = - \\frac{1}{m} \\sum\\limits_{i = 0}^{m} \\large\\left(\\small y^{(i)}\\log\\left(a^{[2] (i)}\\right) + (1-y^{(i)})\\log\\left(1- a^{[2] (i)}\\right)  \\large  \\right)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: compute_cost\n",
    "\n",
    "def compute_cost(A2, Y):\n",
    "    \"\"\"\n",
    "    Computes the cost given in above equation\n",
    "    \n",
    "    Arguments:\n",
    "        A2 -- The output of the second activation\n",
    "        Y -- \"true\" labels vector of shape (1, number of examples)\n",
    "    \n",
    "    Returns:\n",
    "        cost -- cost given in above equation \n",
    "    \"\"\"\n",
    "    \n",
    "    ### START CODE HERE ### \n",
    "    \n",
    "    ### END CODE HERE ###"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
