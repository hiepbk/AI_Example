{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mạng nơ-ron 1 lớp ẩn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Thư viện\n",
    "\n",
    "Import những thư viện cần thiết "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Package imports\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Mô hình mạng\n",
    "\n",
    "**Mô hình**:\n",
    "<img src=\"images/classification_kiank.png\" style=\"width:600px;height:300px;\">\n",
    "\n",
    "**Các công thức liên quan**:\n",
    "\n",
    "Với mỗi ví dụ $x^{(i)}$:\n",
    "$$z^{[1] (i)} =  W^{[1]} x^{(i)} + b^{[1]}$$ \n",
    "$$a^{[1] (i)} = \\tanh(z^{[1] (i)})$$\n",
    "$$z^{[2] (i)} = W^{[2]} a^{[1] (i)} + b^{[2]}$$\n",
    "$$\\hat{y}^{(i)} = a^{[2] (i)} = \\sigma(z^{ [2] (i)})$$\n",
    "$$y^{(i)}_{prediction} = \\begin{cases} 1 & \\mbox{if } a^{[2](i)} > 0.5 \\\\ 0 & \\mbox{otherwise } \\end{cases}$$\n",
    "\n",
    "Hàm chi phí $J$: \n",
    "$$J = - \\frac{1}{m} \\sum\\limits_{i = 0}^{m} \\large\\left(\\small y^{(i)}\\log\\left(a^{[2] (i)}\\right) + (1-y^{(i)})\\log\\left(1- a^{[2] (i)}\\right)  \\large  \\right)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 - Hàm kích hoạt\n",
    "- Sigmoid:\n",
    "$$sigmoid(x) = \\frac{1}{1+e^{-x}}$$\n",
    "- Relu\n",
    "$$relu(x) = max(x, 0)$$\n",
    "- Tanh\n",
    "$$tanh(x)=\\frac{e^{x} - e^{-x}}{e^{x} + e^{-x}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: activation\n",
    "def activation(x, name='sigmoid'):\n",
    "    \"\"\"\n",
    "    Compute the activation function of x\n",
    "\n",
    "    Arguments:\n",
    "        x    -- A scalar or numpy array of any size\n",
    "        name -- type of activation: ReLU, sigmoid (default), tanh\n",
    "\n",
    "    Return:\n",
    "        s -- activation(x)\n",
    "    \"\"\"\n",
    "    \n",
    "    ### START CODE HERE ### \n",
    "    if name == 'sigmoid':\n",
    "        s = 1 / (1 + np.exp(-x))\n",
    "    elif name == 'relu':\n",
    "        s = np.maximum(x, 0)\n",
    "    elif name == 'tanh':\n",
    "        s = np.tanh(x)\n",
    "        \n",
    "    ### END CODE HERE ###\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x = [[-0.41675785 -0.05626683 -2.1361961 ]\n",
      " [ 1.64027081 -1.79343559 -0.84174737]]\n",
      "activation(x) = [[0.39729283 0.485937   0.10562821]\n",
      " [0.83757178 0.14265203 0.3011669 ]]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(2)\n",
    "x = np.random.randn(2, 3)\n",
    "print('x = ' + str(x))\n",
    "print('activation(x) = ' + str(activation(x, 'sigmoid')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 - Khởi tạo tham số"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: initialize_parameters\n",
    "\n",
    "def initialize_parameters(n_x, n_h, n_y):\n",
    "    \"\"\"\n",
    "    Argument:\n",
    "        n_x -- size of the input layer\n",
    "        n_h -- size of the hidden layer\n",
    "        n_y -- size of the output layer\n",
    "    \n",
    "    Returns:\n",
    "        parameters -- python dictionary containing:\n",
    "            W1 -- weight matrix of shape (n_h, n_x)\n",
    "            b1 -- bias vector of shape (n_h, 1)\n",
    "            W2 -- weight matrix of shape (n_y, n_h)\n",
    "            b2 -- bias vector of shape (n_y, 1)\n",
    "    \"\"\"\n",
    "    np.random.seed(2)\n",
    "    \n",
    "    ### START CODE HERE ### \n",
    "    W1 = np.random.randn(n_h, n_x)\n",
    "    b1 = np.zeros(shape=(n_h, 1))\n",
    "    W2 = np.random.randn(n_y, n_h)\n",
    "    b2 = np.zeros(shape=(n_y, 1))\n",
    "    \n",
    "    parameters = {\n",
    "        'W1': W1,\n",
    "        'W2': W2,\n",
    "        'b1': b1,\n",
    "        'b2': b2\n",
    "    }\n",
    "    ### END CODE HERE ###\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'W1': array([[-0.41675785, -0.05626683],\n",
      "       [-2.1361961 ,  1.64027081],\n",
      "       [-1.79343559, -0.84174737],\n",
      "       [ 0.50288142, -1.24528809]]), 'W2': array([[-1.05795222, -0.90900761,  0.55145404,  2.29220801]]), 'b1': array([[0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.]]), 'b2': array([[0.]])}\n"
     ]
    }
   ],
   "source": [
    "n_x, n_h, n_y = 2, 4, 1\n",
    "parameters = initialize_parameters(n_x, n_h, n_y)\n",
    "# print(\"W1 = \" + str(parameters[\"W1\"]))\n",
    "# print(\"b1 = \" + str(parameters[\"b1\"]))\n",
    "# print(\"W2 = \" + str(parameters[\"W2\"]))\n",
    "# print(\"b2 = \" + str(parameters[\"b2\"]))\n",
    "\n",
    "print(parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 - Lan truyền xuôi\n",
    "Công thức lan truyền xuôi: Với ví dụ $x^{(i)}$:\n",
    "$$z^{[1] (i)} =  W^{[1]} x^{(i)} + b^{[1]}$$ \n",
    "$$a^{[1] (i)} = \\tanh(z^{[1] (i)})$$\n",
    "$$z^{[2] (i)} = W^{[2]} a^{[1] (i)} + b^{[2]}$$\n",
    "$$\\hat{y}^{(i)} = a^{[2] (i)} = \\sigma(z^{ [2] (i)})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: forward_propagation\n",
    "\n",
    "def forward_propagation(X, parameters):\n",
    "    \"\"\"\n",
    "    Argument:\n",
    "        X -- input data of size (n_x, m)\n",
    "        parameters -- python dictionary containing your parameters (output of initialization function)\n",
    "    \n",
    "    Returns:\n",
    "        A2 -- The sigmoid output of the second activation\n",
    "        cache -- a dictionary containing \"Z1\", \"A1\", \"Z2\" and \"A2\"\n",
    "    \"\"\"\n",
    "    \n",
    "    ### START CODE HERE ### \n",
    "    W1 = parameters['W1']\n",
    "    \n",
    "    Z1 = np.dot(W1, X) + parameters['b1']\n",
    "    A1 = activation(Z1, name='tanh')\n",
    "    \n",
    "    Z2 = np.dot(parameters['W2'], A1) + parameters['b2']\n",
    "    A2 = activation(Z2)\n",
    "    \n",
    "    cache = {\n",
    "        'Z1' : Z1,\n",
    "        'Z2' : Z2,\n",
    "        'A1' : A1,\n",
    "        'A2' : A2\n",
    "    }\n",
    "    \n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return A2, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.62434536 -0.61175641 -0.52817175]\n",
      " [-1.07296862  0.86540763 -2.3015387 ]]\n",
      "[[0.96040685 0.05002626 0.96641487]]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "X = np.random.randn(2, 3)\n",
    "\n",
    "parameters = initialize_parameters(2, 4, 1)\n",
    "\n",
    "print(X)\n",
    "A2, cache = forward_propagation(X, parameters)\n",
    "\n",
    "# tuple\n",
    "print(A2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 - Hàm chi phí\n",
    "Công thức hàm chi phí $J$: \n",
    "$$J = - \\frac{1}{m} \\sum\\limits_{i = 0}^{m} \\large\\left(\\small y^{(i)}\\log\\left(a^{[2] (i)}\\right) + (1-y^{(i)})\\log\\left(1- a^{[2] (i)}\\right)  \\large  \\right)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: compute_cost\n",
    "\n",
    "def compute_cost(A2, Y):\n",
    "    \"\"\"\n",
    "    Computes the cost given in above equation\n",
    "    \n",
    "    Arguments:\n",
    "        A2 -- The output of the second activation\n",
    "        Y -- \"true\" labels vector of shape (1, number of examples)\n",
    "    \n",
    "    Returns:\n",
    "        cost -- cost given in above equation \n",
    "    \"\"\"\n",
    "    \n",
    "    ### START CODE HERE ### \n",
    "    m = Y.shape[1]\n",
    "    \n",
    "    l = Y * np.log(A2) + (1 - Y) * np.log(1 - A2)\n",
    "    \n",
    "    cost = (-1/m) * np.sum(l)\n",
    "    \n",
    "    ### END CODE HERE ###\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 - Hàm lan truyền ngược\n",
    "\n",
    "**Công thức lan truyền ngược**:\n",
    "\n",
    "<img src=\"images/grad_summary.png\" style=\"width:600px;height:300px;\">\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: backward_propagation\n",
    "\n",
    "def backward_propagation(parameters, cache, X, Y):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "        parameters -- python dictionary containing our parameters \n",
    "        cache -- a dictionary containing \"Z1\", \"A1\", \"Z2\" and \"A2\".\n",
    "        X -- input data of shape (n_x, number of examples)\n",
    "        Y -- \"true\" labels vector of shape (n_y, number of examples)\n",
    "    \n",
    "    Returns:\n",
    "        grads -- python dictionary containing your gradients with respect to different parameters\n",
    "    \"\"\"\n",
    "    \n",
    "    ### START CODE HERE ### \n",
    "    \n",
    "    ### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "X = np.random.randn(2, 5)\n",
    "Y = np.random.randn(1, 5)\n",
    "parameters = initialize_parameters(X.shape[0], 4, Y.shape[0])\n",
    "A2, cache = forward_propagation(X, parameters)\n",
    "\n",
    "grads = backward_propagation(parameters, cache, X, Y)\n",
    "\n",
    "print (\"dW1 = \"+ str(grads[\"dW1\"]))\n",
    "print (\"db1 = \"+ str(grads[\"db1\"]))\n",
    "print (\"dW2 = \"+ str(grads[\"dW2\"]))\n",
    "print (\"db2 = \"+ str(grads[\"db2\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6 - Hàm cập nhật tham số\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: update_parameters\n",
    "\n",
    "def update_parameters(parameters, grads, learning_rate = 0.5):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "        parameters -- python dictionary containing your parameters \n",
    "        grads -- python dictionary containing your gradients \n",
    "    \n",
    "    Returns:\n",
    "        parameters -- python dictionary containing your updated parameters \n",
    "    \"\"\"\n",
    "    \n",
    "    ### START CODE HERE ### \n",
    "    \n",
    "    ### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "X = np.random.randn(3, 5)\n",
    "Y = np.random.randn(1, 5)\n",
    "parameters = initialize_parameters(X.shape[0], 2, Y.shape[0])\n",
    "A2, cache = forward_propagation(X, parameters)\n",
    "grads = backward_propagation(parameters, cache, X, Y)\n",
    "\n",
    "parameters = update_parameters(parameters, grads)\n",
    "\n",
    "print(\"W1 = \" + str(parameters[\"W1\"]))\n",
    "print(\"b1 = \" + str(parameters[\"b1\"]))\n",
    "print(\"W2 = \" + str(parameters[\"W2\"]))\n",
    "print(\"b2 = \" + str(parameters[\"b2\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.7 - Hàm mô hình\n",
    "**Các bước thực hiện**:\n",
    "1. Khởi tạo tham số\n",
    "2. Tính lan truyền xuôi\n",
    "3. Tính lan truyền ngược\n",
    "4. Cập nhật tham số\n",
    "5. Tính giá trị hàm chi phí"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: nn_model\n",
    "\n",
    "def nn_model(X, Y, n_h, num_iterations = 100):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "        X -- dataset of shape (n_x, number of examples)\n",
    "        Y -- labels of shape (n_y, number of examples)\n",
    "        n_h -- size of the hidden layer\n",
    "        num_iterations -- Number of iterations in gradient descent loop\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- parameters learnt by the model. They can then be used to predict.\n",
    "    \"\"\"\n",
    "    \n",
    "    np.random.seed(3)\n",
    "    \n",
    "    ### START CODE HERE ### \n",
    "    \n",
    "    ### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "X = np.random.randn(3, 5)\n",
    "Y = np.random.randn(1, 5)\n",
    "\n",
    "parameters = nn_model(X, Y, n_h=3, num_iterations=21, print_cost=True)\n",
    "\n",
    "print(\"W1 = \" + str(parameters[\"W1\"]))\n",
    "print(\"b1 = \" + str(parameters[\"b1\"]))\n",
    "print(\"W2 = \" + str(parameters[\"W2\"]))\n",
    "print(\"b2 = \" + str(parameters[\"b2\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
