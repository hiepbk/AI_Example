{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "\n",
    "Trong bài tập này, bạn sẽ thực hiện xây dựng một mô hình phân loại sử dụng Logistic Regression để nhận dạng một bức ảnh có phải là mèo hay không.\n",
    "\n",
    "**Lưu ý**:\n",
    "- Hạn chế sử dụng vòng lặp (`for`/`while`) trong code nếu không thực sự cần thiết.\n",
    "- Sử dụng thư viện `numpy` để tính toán"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Thư viện ##\n",
    "\n",
    "- `numpy`: thư viện tính toán\n",
    "- `h5py`: thư viện tương tác với cơ sở dữ liệu dưới dạng h5 \n",
    "- `matplotlib`: thư viện vẽ đồ thị\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from lr_utils import load_dataset\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Tổng quan bài toán ##\n",
    "\n",
    "**Bài toán**: Bạn được cung cấp một cơ sở dữ liệu (h5 file) có chứa:\n",
    "- Tập train gồm `m_train` bức ảnh, được gán nhãn là mèo (y=1) hoặc không phải mèo (y=0)\n",
    "- Tập test gồm `m_test` bức ảnh, gán nhãn tương tự.\n",
    "- Mỗi bức ảnh có chiều `(num_px, num_px, 3)` trong đó `num_px` là số lượng pixel theo mỗi chiều, `3` là 3 kênh (RGB).\n",
    "\n",
    "Bạn sẽ thực hiện xây dựng một thuật toán nhận dạng ảnh để phân loại các bức ảnh là mèo hay không.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Loading the data (cat/non-cat) ###\n",
    "**Lưu ý**: Hàm `load_dataset()` được cung cấp sẵn, trả về 5 giá trị `train_set_x_orig, train_set_y, test_set_x_orig, test_set_y, classes`:\n",
    "- `train_set_x_orig`: đầu vào của tập train\n",
    "- `train_set_y`: đầu ra (nhãn) của trập train\n",
    "- `test_set_x_orig`: đầu vào của tập test\n",
    "- `test_set_y`: đầu ra (nhãn) của trập test\n",
    "- `classes`: phân loại (cat/non-cat) sử dụng để in ra dự đoán \"cat\" hoặc \"non-cat\" thay vì \"1\" hoặc \"0\" \n",
    "\n",
    "Cuối mỗi biến có hậu tố \"_orig\" thể hiện đây là biến gốc ban đầu, biến này sẽ được xử lý ở các phần sau.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading dataset\n",
    "train_set_x_orig, train_set_y, test_set_x_orig, test_set_y, classes = load_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Visualize an example ###\n",
    "**Lưu ý**: thay đổi giá trị `index` để xem ví dụ khác."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y = 0, it's a 'non-cat' picture.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJztvWmQZNdxHvrlra2rep3unn0GMxjs\ni4ABCG4iJEHkI0XRsmlbNC3ZYdMWbfyRX9Dx5BBJK+KF/cKOkP5I1g9bL/BE2XwK2RRtiSKCcpCi\nAG4iKYADAhiAGAxm32e6p/fqrr2Of1R15VJ9b9dsNaArv4iJObfy1Lnn3rqnb+bJzC8phACHwzFY\niG73BBwOR//hC9/hGED4wnc4BhC+8B2OAYQvfIdjAOEL3+EYQPjCdzgGEDe08Inow0R0lIiOE9Fn\nbtakHA7HrQVdbwAPEaUAvAXggwDOA/gBgF8OIbxx86bncDhuBdI38N13ATgeQjgJAET0BQAfBRC7\n8CfGx8OOHTtaB6GpZPIPUCalp1Wqcnt2tcHfuc6JJ4KuR5TwpVswj5txvls8vBqENv74loCue/ze\nvngr7tvNvCWr85dQXl3cdMgbWfi7AZwTx+cBvDvpCzt27MDnnvl/AQCNalnJahU+3jk+pWSvibM8\n84OlTrtuVz7FPGzmA0q61VHC8o55quI+v/a+bHmFhH5yjKTxtCgY2bWPb+1CNaIZT48hBfHnSppH\n0uf6XPGvg+s5V0u2cftmjZ9KmHP8GBuP99Xf/kRPY93yzT0iepqIDhHRocWlpc2/4HA4bjlu5I1/\nAcBecbyn/ZlCCOEZAM8AwKOPPhoO3HMfAODi2dOq36p4f1wpLirZnsnhTvs9e3Od9l+fr6p+DfGH\n0/6FDTH6ZrLqdn1/wXvtlyiDuhglC+pda8fYWHYt84h9rySoUXZ4NUbsQfI84mTdb/z4ScYNmTyG\n7Zsk6+0e63tl3vBxmk3CuW4UN/LG/wGAe4joTiLKAvglAM/enGk5HI5biet+44cQ6kT0LwB8DUAK\nwB+EEH5002bmcDhuGW5E1UcI4X8C+J83aS4Oh6NPuKGFf80IAVG9BgDYd9c9SnTh3OlOe3lhTska\ntVKn/fMPFTrtbEZP/6/OcL9GSDA61cfxewHXvwt84/a/7ni94/f2HSuLYr7X5URJsPGlDXm9Hor4\nXf2uT4SsN+/FzRgjeXz7owUh06K4HZsu71PintAGAyTAQ3YdjgGEL3yHYwDRV1W/sbqKpb8+BAAo\nPPSAku25Y3+nPZvNKtnczJVOOzQrnfbPPVhQ/VI01Gl/52xFyWpW9V9HkivrVrvsrnP8JNW5Zxee\n0Oe7tV6h3vfo5rpeV1xcv25ZSOiXJLvxMZLv48bBN9fieVP3B/H3PmkeYvY9ndPf+A7HAMIXvsMx\ngPCF73AMIPpq46ejFKaHxwAAy2+8qWSrIkln2747lCyTyXTaVy5e7LQbTZ3o8/57ud9yLadkL12q\n9TTH2OSS1iebfqdb1nvfuLDipH2IXmVJl9I9x407XlPIaIxdn2xbJw3X6z5B0vF1hjDHxjBfS8hu\n/Pg3Q3at8De+wzGA8IXvcAwg+qrqExGoHW03MT6hZKtnznfay2slJdtyH0f5pTPs6rt04Zzq16wz\nScfBvUqEs0X+G3e1yCQgN8fdliTr3TUUn9LW+7xiE9WuwW15PbwDvbvzuqQJsrgx7HyvPQe/O7Iu\nfh7JbsDNz7WZLGYasHZFkuxa4W98h2MA4Qvf4RhA9FXVr1UruHL+NAAgPzauZBMTTLdVntNMPUuH\nOdt37KH7O+29+w+ofhcEuce+qbqSPbab1bXnjwuKqwTWo+tV3eTufFeUXc9q+vXtpqu+SWpjr3O6\n7qi7jdXja0uAifu8d9U+VtVPeuUleWL6qurbaW3upen1UfE3vsMxgPCF73AMIHzhOxwDiL7a+JV6\nHcdmZgAAx7/1nJJ94Kc/0Gnvu0Pb7ukKk2oWX2V7f/ih+1S/fXfd3Wm/cfS0kh2fW91wTsnuNZsV\nJ0QJ/ZJcVNdF6tBldMYOERutd22RavJCe7Onu+6AGjM+Oq/325/g9lO/S2/XkjhGUjRkwiR7369I\nctPJXvG/u00KTMqi3Aj+xnc4BhC+8B2OAURfVf1mlEa5MAkAeDMaU7Kh77/Qae/ZtU/JMvl8pz1e\n52Sb4us60Sd77118rsJ2Jbu0cqrT7p3rLl4lS1L1EyOsAkcXNhuaLCSK+OeI0pxkFJoN1Q9NvgdR\nJq9l4nwJRYHMPdDlzFSVIzHHKJVR/ZSamy0YGb9Toij+/ZKYAIONb3gSF12XKSFNhITXXJLLrndV\nf+PPNxsj3sSL72e/sn5pvWr8/sZ3OAYQvvAdjgGEL3yHYwDRVxs/ImAo1zpldlTb+IVsqtMmYxPO\nz17ifmOc1TeW0/bt2rGTnfZydcSencdPMIS0y876TEQYcIPt7Fpp3vRjmR2jtMDlBdcWLynZ6BSn\nFGbGuF2taFdkY+0qf2fPo/rcdXZ9hmqx066sLJh+Yn+hqUlKyouz3G2N6xim0/pxyQhS1KFtdylZ\ndmxbp53fIWRRSvVriv2LKKVlEM9B8p5KQi3BGHdk8r5DkqWsx2vWOZO03uB7n84MqX5I8/4Ikb7O\nSMwxqM/tPkFvWYK9YNM3PhH9ARHNENHr4rNJIvo6ER1r/7/lhmbhcDj6il5U/f8C4MPms88AeC6E\ncA+A59rHDofjxwSbqvohhG8T0X7z8UcBPNVufx7ANwF8erOxKIqQL7RUoGxOc+dH0cauGwA4IbLu\nzh1jF977P/xR1W9yemunvXBeq8dNkYYXhEutUV3R/WqsHqM0q2Sp1cv8vTJ/b2VVZxPK8Ym0q0yq\nthlz+6M5dqOtXTrK4xn1ksBjrFw9rmTlEqvwQaj9TeMSTEnXkElRlOdLi9+iqb2PqKzxe6O8fFXJ\ncqNskqWrbN5QSptnVVHbPDe+TcmiIc7gTAnVOcoNq35SdU4m2Ehw2cU/fjrDsqp5HotHnu+0mxk2\nL8fveFiPn2H3bMpOMcv3hFL8TCS5JmP9drc4O297CGHdQL0MYHtSZ4fD8fbCDe/qhxACuuspdkBE\nTxPRISI6tLSyEtfN4XD0Ede7q3+FiHaGEC4R0U4AM3EdQwjPAHgGAO47cFegdEvF37Vnh+qXvco7\n411RSVt3dtpvvvxyp333WydUv8ntQvEwO8SNCo+/cvFVHnvltOqXJlaPq2XN/ac3j/mg2dDqfK3O\nxylzMSnxp9ZG5BVLYkdeDGnvR60uVHGrN4aND0JD/22WZ06l9RhBmkVCjU7Z14ToVxVmBQA0VtlM\nmjvNHoVUUw+SyfD49UvG9MmK6MUUt7PDmq8xZFnFzrUjQzvnG2XzITXEnqQooyMNpSpuQ/yUGZDR\ntO1jB97J44/wHneU1qasSjKqay9KKPLyKRfZZBre9ZAeIWXHZES1tmkbmrF9VP+eenXjWQCfaLc/\nAeDL1zmOw+G4DejFnfffAHwfwH1EdJ6IPgngNwF8kIiOAfg/2scOh+PHBL3s6v9yjOgDMZ87HI63\nOfobuRcRCrlWBFNoaPtWlW02Ru30VradJnexvZ/Lm8w08b36knZz1U9y9l9uda7TzhhGg6Ecz6ua\n0/NYWhaRe+JcKbu3KcysrLmWirC1MyZ9TtraaaGLlevabsum2S4ezmqbsyxKkVWqwgY3+xCNpnCj\nmXmkhTFfqZnMQIHhIX58MuYWVGt8vkxFujd1x6IgWTHmP6IM77E0Awszi3O6owi3zJm9nUjUYSCx\nT5DOj6p+uQneC0iPaSdVZpTdxOm8jjhNjbMsMhF5EvKZTpky8CHF54tWeG8kMq5g7c3TMrrc2vui\n2lrsHCQ8Vt/hGED4wnc4BhB9VfXr9ToW5lvuikZRJ7akE1wV6SwnOORExF/aJFooHgSTOBOV2GVS\nqbKaVG1q1fPhHazOv/O9OgHm+RevdNqvHWO3S9Wo4tJsKRlVuR5xX6myA0BZqOapLF9b05gjW8dZ\n3XzqJ9+jZN978Qed9qkLrDZmTc6IqDaGyIR7yeOQ4vnmzXylVh2ljbtQjJ/LiGvpshz4XFnjRpO/\nU6nOv0va+BVzItoNdvyqdMlyO1VcVt1Kc1yF2bqC00NDoq1NhMzYdKedn2AXdW7CuKulCzKtfwxp\njuRGebyuJDFhJkXm+V478V0AQLOyMbekhb/xHY4BhC98h2MA4Qvf4RhA9LlMdoR025Uxd1VH+e7N\nc+08W88uJWwuGeIZ2dBKaZs2dO28SpnDJKXtOJLT9tbde5/otO/a/w4le+AxTk/7/T/8Wqf9wg8v\nqn5rZTY0g7Gf5R5FJqvJK/P5jWUjw5pUZGoLu5D23LFHyX5xB7s+/9MffrHTXizq8GMZlmumoVxx\nhTzf47R5TaxW+Z4G86NFwssYCRt/eFifLCcIKmxscl3sv9QaLJO/HwBURdZgo2HTRoSLV4SzZsye\nRFOM3zT7MmlBsNEs6nyTMMuZh6l0h7IC+YJ2NedHOJQ4PazpKwoT7M5LN3mOIaPvVSRCk9MXX9Gy\ntZn1yaMX+Bvf4RhA+MJ3OAYQ/Y/cG2rpgCPDhoddaFc2cq9aZhfFyMiw6KeHaFZY5xte026Nu4Uf\nKSeinqZIZ5VNR0K9ijThw9jEnZ32r/5zlu149tuq3+mL/Pc0N6Qj64aF2p4xqpzmYhNRfGmj8gnT\np2CiFx95jMuKvXX6dKf9589/R/VbWWFTqEyGpEO8D3LCrWjLNEkKwqY1z2RmoJBlMsZ1KJ7Aphmk\nkGFhECcn7VFDQ5xgZUWbAcurfExCna8at5+MUIwiG20pTMimzX4TdQzSrGZLcwkAiisioi66oGSZ\n6EinnZNRk6SfnbxwK+5unFey6cmWqZxO9bak/Y3vcAwgfOE7HAOIvqr6pbU1vPHqSwCAxauaoy1M\niN1pW6VWkDysLPD3mhm9O3rlNNNrZ14+rGQfEqpnQyTDBJPskBGZItt37dayITZPmk0e4x/90t9U\n/V5/83SnffysidxrspreNGpjXSTS1JTqGU8MYSmYJ8d4jn/3Iz/XaZ8+d071e/EVJjGp101k4CR7\nF8YLbGZUoT0lJbGDXinpaxkRZsyQjPgzKrZMQEqbyMCG+M1kpGHaRhoK9XhiXN+rMZFTs7DEg8wt\n62tJKq9VF2q7ZQBXZa2EOdI03oUgzAWby1MXZmg1sLnagPbETIno1kxd06WHzB2t/5MuRMDf+A7H\nAMIXvsMxgPCF73AMIPpq4yME1NvRXm8eeUuJHn2HJD8wbp0CuzHyeW6Xy5rj/MRxtltnZrUNNCEi\n5kiUgiJDUFE5wnsDCyc1z/vdT36k085mOYtqwVSneuShuzvtXO60kr15kl0+q2valVgQewirIT4q\nTpr11rmUESWq9u3kCL+//1G9D3Hq7Oc67ZWidn3KTLhhEa5ny25nh4Tbz5TXGh+Wx8LlZchNUsL2\nzQ2ZyD1xe0hkCYam7tcQ+zLWfk4L9+H0lCAOMcmgM3N8zRUT/JYxc1bji8tU5a9s9TW5t2FkcgtH\nukjzOX0xhQbXbxgf0a5mG+26GfyN73AMIHzhOxwDiL6q+hOjY/g7T7VcTD9xn+YMb8xz6aquEkZC\nj5Gy+TlNRvDyIU6SKJR1vadh4fLJSn4/mOqti6xO1VbOKNnMBU7M2bKVCTC2bdup+s3OMmHHfXfd\nrWTp6Fin/dIrOlHpobsOdNpvnWW35cJyPI/aWkmbCwsiGWdylM2iRx+4R/W79+79nfYrr7+hZJK3\nX7Ztgs3WHB/b4rOKFEW4mIIh1stKU8Lw++ekGi1MAkPXiHpNPB9G520KF5skGJkYM6QiYloz8ybB\nS4xviUQq4v6kUvEmhzLPjH0mAxaliTCS0R1zENV4h7cqWWhHnPZaRdff+A7HAMIXvsMxgPCF73AM\nIPqbnUeEQpuI49H9B5SsuVdkURk7JSPrpgnWyNnZy6rfWpFt4XRdG2M14bZLC0KGlPnbl+QVITAJ\nw8Lstzrt4fFHVL8dOzhD7uqc9vUd2H9/pz0+rLOvKMXXNj5+V6f94mFdI3Bxmd1vtbq2R68u8Byl\njV/I6OusSxINY3NKu7sgDO2MMVwlX0WUMkQcMkpX9Mtn9TwkcWYzwTxVrjJzrqwk8zQZfvIoBblP\noPuVK/L507KRIdlPT3JVhirLeRkbX4b6Vs2zKecsPXiWgHZ8kgk8G2ajgO9Jb369Xkpo7SWibxDR\nG0T0IyL6VPvzSSL6OhEda/+/ZbOxHA7H2wO9qPp1AL8WQngQwHsA/CoRPQjgMwCeCyHcA+C59rHD\n4fgxQC+18y4BuNRurxDREQC7AXwUwFPtbp8H8E0An95sPOr8byK4hC5k+cS3pDii7Sf2snvs8JEr\nqh+EOt8wKp/MhFNkCpFWmUjIKIl0IWJ1bXX5ZdWrXmU34/TUO5VsaYldYFt36OirkVFWmuaFifCT\n77hf9fv+y0d5Rrb8lSDtKIkQtO5SWHxtlkRjfFRENqakKmvcS8L9FhnVVg6pCDxMSFtDkIBYoo9y\nRZQAExlyw8P6fZVKKAcuVfiM8Dna8uJTW/gCRkcNb39OhtZp2fwCz39+kdtl7WVFU8zR3m9VQluU\nzdoxrbkWMyke1Lotu0I4N8E1be4R0X4AjwF4AcD29h8FALgMYHvM1xwOx9sMPS98IhoB8CcA/mUI\nQZUhCa0Imw13FYjoaSI6RESH5paWNuricDj6jJ4WPhFl0Fr0fxRC+NP2x1eIaGdbvhPAzEbfDSE8\nE0J4IoTwxNT4+M2Ys8PhuEFsauNTy7f2OQBHQgi/LUTPAvgEgN9s///lXk4Y2q46+xcnKCYTLUsJ\n98f+KbYowuPajXb4pddYVjODSJsoweMhbSebFafH46bNWquWT3fa81d0jbbxqXd12o2g/xCmhPtm\n+w4OA6YZvZfxnoMcfnv5imYyqtXYri+JWgKlqk45GxuX59KhuCN5UbtA2MIZYxfnRI2DhuXVl10l\nwaYthS1+96YZY7jAsmHBymn5/WW2nvGUIYgTLs6xjZwxVDrjW2R9RsN4FMl7oGUTIox5B1Pn4/JV\nPZH5Ip/bZv/J/YZh6c9raldtU9j/llSzuV5HoscsvV78+O8D8I8AvEZE6yz+/xqtBf9FIvokgDMA\nPt7bKR0Ox+1GL7v6f4XuvJl1fODmTsfhcPQD/SXioG4u/I0QjO5Mwv+RErKcqf0kVbIuNV1m+Cm1\nP75f2RBIlquCEGRIqHKWKEO6bgwp4sIMR/yNbnlMyQrjD/P3xKm3b9cOE6kejxR09F9plclJZASk\nVQ0fvJOJRFfnNUd7pDRzPkiZEL/905whduLqopJVmpwdKVX4UkmrwCMj0nVoSDSFfy8X+LeuGxVY\nRuHZx0s+O4pU1FyLfF6qJa2Lp4SLNJXT97Eh3JN5YZocuEM/m9vX+PjURZ1tKec/PSEIXU0ZOOlJ\n7NLoO0wfNylyz+Fw/O8HX/gOxwCir6p+s9FEcaW1yz00rKPWMilWheLrneqjtNmZtfzzEgEb7+on\nKUYLC0V1/MpzzMf3jsf3dtq7dpiaTpqGwkyEd3dXl19XolFRoiubneARjH20bTsna8xdnVWyjLoH\nIloxaBX7qfc91WlXl7Xn4cIF5uCvyVK0hoVi7zRHGjagE0qeP8ycilXBnb+4rEPadm5l82kib5JS\nlvm+3itqHLxe1QQppRSTj5B5BrLCozAxzs9YzXp9xKUNFbSanhLJSUPGpVAqszreFJGMNommJu5d\npWLC+sT7dyTPS7Je1WQyDeFRsJGpaWP+bAZ/4zscAwhf+A7HAMIXvsMxgOirjb9aWsMLh1sxQLPz\nc0p28L4HO+17D9ylZNIck9Fi3a5BWROvy7HTaTVllKD92ydcSNmszo4iYht0dpYj5nbu0BF46swm\nbY2ErW2zEBt14UYS5m7acNZLm396alLJ6kXOhyiustuoYYgsp8c5MvBnf/4XlezYW2yfnzj+V532\nlfOa+GRiC+9DPDGp6RhOzXAE96UFnlPBkI80he27tqrt1HFROm5liQ8WlrSNvJRhF+boqP7NogLf\nuwmRdYiMIdRs8Jj1ur7ftVXpptMklyt13gcKwrW3UNVznFkSJDEVvXckafsbq7y/0Ghqt2IjLWpD\nwOxDtOdPllUlBv7GdzgGEL7wHY4BRF9V/UognKm33Dc/uKgj2qIGq5dp8/fo1AyrmE889ECnbRND\npMvOqtGhh7b9xJKF5Ee45nImUxH99CjFIqueZy9ole+eu9gsyBj2hJdffrHTfujh93Xa4+MTqp8k\nLQlprfLJsLvCEKuGWXNPawVWibfv0ur3iFCXd+7m9l/++ZdUv5KoXXDnrh1K9tBWnnNFcP0jp+9V\nLs2mCtGQkiHie1cVqnjK2Hj5DH8vld2jZdvv6LR3Zzi6MKprdfv1sxy9+NgDDyvZ0hKbBRdL+tzZ\nUb7Ow0ePdNq1q5dUv6aoB5Yzv/uIcNOlm9yv1kUmw8fphi4fh2CJVpLhb3yHYwDhC9/hGED4wnc4\nBhB9tfGHcjncfU+LT/9q0K6KEeEKOXf+gpJdWmTX0H89ymGuj+zar/pRgvUuM/Ik32Nk3R9CZsM/\nh0c4hJTAexSrprSdLNv82hvnlGx8lG2zPXu0PXp1nsdcWWF+/JER7aKSczTckihW2dYbFnzz9oeu\nir2BRlrb+KPCZTqUZ3v34Ue0O682L34nQ1Cxaxu7vV55jesFRjV9vzMj7Aac3KrdomtptsMXRUnx\n/JAOkZ4U4d87d+tMxuNX+J5WJuLDgx85wGOsmh/06gLvUUxNTSvZyZOnOu2VCxxKHJnQ3sIo7w/J\n+wsAWwKPnxfkr8VavI1PJkQ3rO8huDvP4XDEwRe+wzGA6LOqn8V9+3cBALbepdXc6pvszttS02pM\nZjzfaX+/xGpYpWbV9HiCDW0EyKw1w68mh6iUlGzPNnZZFZc4K65UWlX9UkLNWzMRXDpL0Li2cqxy\nl8tsEly+dFH1W1xkt9TuPXco2Y+OHu+03/Eg1yCwmYtrJb621Ih2F8pKWVlhBYwbNXd2gV1gNcPp\nV6ry/Msl4TqraTV3SZQivzKruQXLIjqtKd5RKRPJOCFcmCfP6nJj8yLzMN/gaMVl0s/O1ASPubiq\nsxUrVb5XR944q2TLy2yShbSIKjXZeVvH2JSYMtGWE4Ljr7LMpgmZCD9JaCLdgwCA9nEiT6SAv/Ed\njgGEL3yHYwDRV1W/XC7j2NFW+afvHTmuZD/1AEfkPbpvr5KVZgSZwizv8KebOmqtKUsRmXpMjRgN\nO9jYPXFYrWgihBFRAnV8jHfaJ0y5gOIa76w3u8pwMWz5q+1bt3Xai4uc2BKZBJiKMIWsCl8TvHJX\nRXJMMKQlp1dYpdxxp46YS4Gve0RE2lUpPjqsax6iZFdV0F83K/p+pLOCzryid9NrVZ5zbpS56Gz5\nqKuX2NswtlvPY3SYH/GLF0+yQP+0eCvwB/W0FkrOmKsL2gytlwW1t6A2j0xV4CbxsU0uozk2caKq\nvAf2GebrbtT0HENtfVffVX2HwxEDX/gOxwDCF77DMYDoL68+0DFwLOHgygq7LijaqWTSfZMvsK2X\nKiW57AzJheS6h4ziix9jdUW7dSKRJbhjN+8vpFOW6FCU2qbeXY7DwpgcynMEWj6vbfDiqnbzSMiM\nQlkOvFw1LtKI53/yrI6UHBdc92tZ/p0aJiosO8S+vmFDnirJQupiHmlTJjubFvdqSEfTVcQcV0pi\nzyOt3ay5AkcJLq8Zzn2x59Fo8PhLa3oMEpGkayu6RkBDuI1Dw5B5ZkVpLxGRVzYhlbNF3vOYzOji\nsfUin68h9gKqDX0/JJqG+DQ0Wsdde1Yx2PSNT0RDRPQiEb1KRD8ion/b/vxOInqBiI4T0R+TpKdx\nOBxva/Si6lcAvD+E8CiAgwA+TETvAfBbAH4nhHA3gAUAn7x103Q4HDcTvdTOCwDWdctM+18A8H4A\n/6D9+ecB/BsAv5c0FhF1SCQyGe2Ksxz5EsOjnJRREO2obFReGdlkVXglg2gb1n7Rb3xYu9G2bmVu\n92aDkzMqxuRoCDfUjmkd7ZZSqq5WnaVLbHiEVeeUcZVZnn09BrfzQhWvrmr3z7gg21gra7VReiAv\nz3CEYgO6X1W4lC6YqsBZkQSTLwh1u27uleAZlGo/AAThc5tfYY7GiLSZODLGUYLpmuUn5BtSr3ME\n6NyijjScHBPuNuhnMS3U+XpDz7EqVO6muLbymimJm2M3Xdm4RWvCHGyI0FHrCpbHIaUV7LDuFqXe\ntu166kVEqXal3BkAXwdwAsBiCGHdoDoPYHfc9x0Ox9sLPS38EEIjhHAQwB4A7wJwf68nIKKniegQ\nER1aMptlDofj9uCa3HkhhEUA3wDwXgATRLSuA+0BcCHmO8+EEJ4IITwxLnKSHQ7H7cOmNj4RbQVQ\nCyEsElEewAfR2tj7BoCPAfgCgE8A+PJmY4XQZJvO2C8ZRVyg7cBIuHWGh9mdh9neNQht4wtbycxD\neqzWZrVs7pywd5tsB85GedWvKTL+7tym7cX8EGdz1U2G1cw81+a7fPmNTrti9jIuXeQMsaGM5sSX\n9r+s32ZruWXF/R4d0UQcFZFNJ0lA6sv6cVktcr8Tx40LTLSbYBs8ldVjNKpsq64U9e9eK/P9SQuC\nkVRBuw7TkSgtXTclqOsivDktxjNPvqqvEJk5Sttaf03ty5RFxmNxTc9jeJzvQb1pePux8fiB7D6V\n+E7W3IP1dzDF75Wp/j302Qng80SUQktD+GII4StE9AaALxDRvwPwMoDP9XRGh8Nx29HLrv5hAI9t\n8PlJtOx9h8PxY4a+Ru6FZhP11RZpxXhKu6SaQk06c0lzuzVHWa2pCC734YbJFhO6kCUkkMdBuGSa\nJpJMEijUy0b1LLGqGAmGimC2SqT6lzGlmmS56qUlTTzx/F9+sdOulNmMqdX0+EHU17rzgP6bPL6F\ny49dXeF7umRKYZM4tvegXGRZdpqj4oooqH5zZb5XqaCj0ebm+XeSkZKpyLiohFHQKOt7lS+xiTcR\n+BkYnbpX9xti2dUVXXq8WJMRoUKlNpGj84LgxZKzNBo8r2pF89mPC/cyCTXb8jXKZ5Ny2jSsC7NA\nuuwakXYJ1sU8GkGbZ1GId/FisE8WAAAgAElEQVRuBI/VdzgGEL7wHY4BRF9V/WaliuKpFsfaNqMy\nXXr9lU57xmydPvFzH+q0R2XkXqTLcMkEBctH0IwxA2x0VCSq2wYTIReJ6MKUiDwkQy0dRPSU5NED\ngEyGx5xb0Dvhs3O84z8kdqCbwf5MfExm51cmMa0JmuiUKbWVabBs+eQbSlYUNN+le5/stI+SrhSb\nnmKzYv7M17RM8sjVhUlmNp0pxXyF2YI2JaIG37shcYsr89qsCCl+llZM8k0zLQhBRLJN06jzEcnf\nXc+xIUzDXE7PkVJ8Xwt5fjazeb3rHkXCe7Gmoyjz4tx15YnRpmxDEJoEM8l6aI3RXSV6Y/gb3+EY\nQPjCdzgGEL7wHY4BRH/LZJeKOHH4e60DY5tGwk4u5HTJqIxwd9w5xXZmZae2laZ3MlnlStAyEm60\nRgIZhozqs/a/NKuku4ZsRpTYG4hMFFhB2H6SfAQAxoZ38Rzr7NJsmDoDKXGvMmltNO/dw0Sls7Mc\nabiwoPdDhojt5+kHHlWyk29xueftkxxmTdkp1S899c5Oe1mb/7jy2qud9iMZvo9Hjmvee0VUYshH\ny4LgZGhcZBoWdB2Dcnm+066V9G+2bXpfp726RqKfvh8ySjBkNPFJaMoMP21310VGXkbMN53W2XND\ncq+HtJuuOswZnBWxCVKfm1X9ikV+pkcNmefCYmufo1b3EloOhyMGvvAdjgFEX1V9igjp0bb7w6j6\nWj3W6mtJlGeKiuyu2f0OraJ+/CGO6CrNaVVudYb5+JfOcQXbhQu6PNWSUI+rhnQhSFVURmalkv5+\n2qg7vu7t23Qppb//sV/geSyy+jojagkAQLnKauPVWX2dS4t8vG8fq7lTU1pNv3yGVe7paU2lkB9m\nt9TlGqus79m3S/WbXRK899ufVLJvn+V7/PBOHj9vHrkfXmKu+5Jx8eYneM7T05wJXqxoFXi1xKW8\nptL6Ondu5TJi+/Ywl+Pz3/y26jczL0phRVrVz6T4OFs1PIwi6nF0hCPydu7Upc0k0UzKpPqsla52\n2pUymzH1ijZpqmvcb3ZJj5FB+5loGAKQGPgb3+EYQPjCdzgGEL7wHY4BRH+z89BNgrkO6cixZadf\n+MZznfb0Li6vfcdBbeOP72Uu+oape9cU5aqbJbYla4s6/POtl17utF9+/S0l2yJDeKVd35WJJZqJ\nEZRaODTEtmR+B1/nrl37VL/Ls/y9Sxe1XXz+zGn+3m62rS25qdxrsNydMruwJogsbMbjq4f4Xh07\n/AMlmznPeyezYn9hZPJO1S+zKrj/Z/Xv3ljlvYbVNNvWlYq+39Uajz+a1yxPly+y/R8ESYcMfwWA\nFVGeum6eHUluMRZpd96kcCFHInwXJcOdL7JRlywPZ1O4EuvSdWvs+MD9ckPblGxk608AAFJvnkYv\n8De+wzGA8IXvcAwg+l9Cq80vZjV+SWbRMOrU1aUznXZ+TGTFpXVEm8yICnmdRRWHsFefa0ioWlWR\nLQcANRGhl5eRe0bVD82NMwG7Ye0Ayb0mVGzTq15h2cULWqUsNVjtffxdwh3Zna7YaTZMuaeqKHFd\nWmP1sj6jCVK++id/2mmfOasj8nLCtKiXeLzsmFbFm1U2RwojWsVOC3dWfYFdWXUTDbm6xBGQy02d\nnTc1webC7Axz819d1Jx4JJZCaGrzqSH4CZdNeuGouFe1OZ5jYUXf0/QWdt0uFvW5x0VkY6rEGZsU\ntHlGYl0MT+xRstRYy1UpswWT4G98h2MA4Qvf4RhA9F3VX1durfoaJK+1iYSTSSmSnjmdN2WEeqwU\nKpNqUhl9C1I5EbWV1WpTU25/x7WhyTFsVdOmiAaMDP+cjGYMsjSTmT9EtFjd8A6ePsWeiG88z94Q\nW3ZrTfAHvpae0GOceLPTlh6WZvqHql9BqPM7JnX03/jYeKd9YAe3L69prruC2KmOTLXcFZFIc3We\nd/UbJrJzWezI26SokTwfy6rLms4d2C4qBBcrhmtRRsOZhKwlESEquQvLYzr6Ly2SgFbXtPdiSObv\niMStWtaQfuT5fjdTmrcv1Wh/L3iSjsPhiIEvfIdjAOEL3+EYQPTZxg9Yt+5tcp6KcDPhbtJqWRPZ\nS+eO68i6SeHdm9yl3R2kynDH7wWoaVhufmEnK67Ga4jOk7z6zaDtc3VPZL8uQlC29cp17QL73otM\nnHnuMruXPvI3Pqz6vfnWsU47s0Vnkp2+cKnTbpQ4M7BOmjh0XmQyLq9o12d1ld2M2cAuxhlDMLok\nynePF7SNnxH3eNtOQcBSsbUK+MYtLGtX3MlzPH+537K0MKf67R4We0dp/bssL/Oc08bGJ0FiGjL8\njC2XTVRmjq+zXNGhe3LGabEHVDbXWSI+nrt4TMl239neD7jZNn67VPbLRPSV9vGdRPQCER0noj8m\nouxmYzgcjrcHrkXV/xSAI+L4twD8TgjhbgALAD55MyfmcDhuHXpS9YloD4C/AeDfA/i/qOUbej+A\nf9Du8nkA/wbA7202FitRlohD/A0iqx5ze2aBVbc/+//06d79s+/vtJ/85V/Rw6fYNaJ59U0ZLq1v\n63mo43j9XvP7x5fyomA5/SSPX/y5ikVWU3/4w8NK9uZRVu9PnOJIu5Mnz6t+BRHZ+Cu/8oCSTRf4\nuFxiM+Avv/WS6lcRKmu1rAkqZs7zHLNpJsNIp7QrbqLAxzaRqCb47Bbn2M1VMeWvioKnvrhmou4a\n0mRiVdkmJs2uiijBqjafajVxPmslNlg2lGa35byJziuQiGSsaxW+JngTI/FbNxu6X0VUDKb5s0p2\nLteKDKzW9L2JQ69v/P8A4NfB5vYUgMUQwvrMzgPYvdEXHQ7H2w+bLnwi+gUAMyGElzbrG/P9p4no\nEBEdWq3WN/+Cw+G45ehF1X8fgL9FRB8BMARgDMDvApggonT7rb8HwIWNvhxCeAbAMwCwe2Kkt9A6\nh8NxS7Hpwg8hfBbAZwGAiJ4C8K9CCP+QiP47gI8B+AKATwD48mZjpXJ5jO9/EABQT2vXUCPFx82U\ndhA0RRhmXdjIq6ZO2pU6h0mWjMtkWEdQdmBtcBnaamUy3Fby70ddilPYoLV+AnkuK5LZefEIFb7u\nveM63Hb/R7ls9vAIX/TSnLY5m2ePd9q7ScsOPvnuTvvKFd5TefbZr6p+83Nsx6eCtq2HRDj1gnDh\njY7q+S6tsk26tDKvZGUR5lqr8+/ZNCSoitzFkoqItvw9UyaLLQj7v2r2fTQ1hqkHIVytQwVZL09P\nZFnY/F3h0yJ0uy6y/Zpmz2NR2PhDZuXuTG101njcSADPp9Ha6DuOls3/uRsYy+Fw9BHXFMATQvgm\ngG+22ycBvOvmT8nhcNxq9DVyLz08gW0/+TcBAK8dO6VkMkpp5qqJ7lpmNWnfbuZGP3ZJq/qvXWYX\nRzH3V0r2i3/7qU57bEyXMJYgqSxZV5xQAaWbyFLuqe9Zr6XuqI4ajY3dTRTpfrk0C3dN6dpVjUkm\nfFgr8X2b3LJF9cuMcfmrxZTOAps9wtF/stR2cVlHu62tsgtvcosm2IAgjVgRP9Piqq4DUBUbvjVT\nnqopyEKgOEVs2KdwkXa5YBmUQIoSRDRkfnhcy2TpaltrIfD8C6I0eMaUgUuLzMDiinZ9Lq6wmSSf\nsaEhfT8i8VAsVvSzv3LiRwCAsvk8Dh6r73AMIHzhOxwDiL6q+rl8DgceuAcA8Kdf/66SXbnCKuCK\n4UOT0V5Rk9t37dmh+pWFSXD4iI5UA32n0/x7f+dnOu0Rs91fEklA5bLeqa4LVbxe411mSpmdXqGm\n2wQbmURx1Zg0P3yVeevGBZHDOx67S48/xDxyDWO2FEWyTKUso7h0NFoQlNGnTBmxbJZlL77ItNnl\nslYjJVXfQlHHaKSFJ0YHZer7kRVkJ7byr1bUk6ImWRZZkVCPGyJirmgi6xpNsRRILwtKCQ+Omb/8\n3soq359JQ/QxUmDiDEsCslbkqMSSuMdVE/ci713TlMqqlVsRm41Gb7Ey/sZ3OAYQvvAdjgGEL3yH\nYwDRVxs/k05j1/aW+2lqUrtMykVhT9eNm6vJf59Wimyr7hauPQCYabBdv223tv9fOcplm3N//q1O\n+8592h125SJHHtdq2o6qiqytWk3w+xs3UUr494LNwBPumr/45o+U7FvfZZLLn7if519f03+fz59l\nm/CF1zQBRrkqXE/iPlarOmurLgz0Q69oEs09u/jcZ85wTYMd2/W92iPuv41Gk644aVvXTGaadY9J\nRMJg1+3I9OPjyMxDkpGeOcMEI8vLRdVPugS73IUq2tIQcQhZqczXtkiaUHPLOHccymmizEyGo1Yz\nq/x7rq7omglB/GYpQzhar/eWlbcOf+M7HAMIX/gOxwCir6p+FEUotN0au3dvV7ILF9id18hoNaa4\nxip3Q7g4Ls7oKLCy0MkuHTmpZMNDPObv/8F/7rSvLmhV+cl3H+y0R/N6HitFVt+GhBsqGJddSuh/\nqUibC2trrK6VlvXf3W3D0512Y4XVwee/qaMc3zjGBBunzmuXYDbH84qEWlo3cyyIhJItRk2c3iI4\n8Q8c6LSD4UKsi0i7unEjSYKTpMq8smaCNRd06YIEVV+RV+jrvHyFow0vixJa9br+XSLlc7QRfuLc\nZM26jUuRrZWte5Pdh+M6qA/pNLtuC6IMXNqo8yvLrPo3G/o3W7dOek1/9Te+wzGA8IXvcAwgfOE7\nHAOI/pfJbtuau3dp11AqwzzhxTVtu5fKbI+VhXvs6DHNLX7fXTzmX39XZ+flhthmHkqx/fkzP6Uz\ni9/7Xs5au3JJkwo1q8LVMnO6066bP58yJNNUOsb5q+y2PLhfk1w+eOAJPleGbb0XX3lD9Ztc4kGn\nt+n6AdJ7KN1EhWEd2pvJsiyd1sQnKREiLfcGGnVtP0t3p63hV5ekJTZsWUBa9db+7+U7ANAQ+wlX\n5/Sex0VRW0AH/SblSZq9BknOaj19YtLSJrd7HmW5pbBiXH0jfH/SoiZeM6vDyUcm+Fyry/o6K9X2\nc9Wjke9vfIdjAOEL3+EYQPRV1a9WqzhzthVBN2l8Gtu3sQtpZVmr+rUh1pPGR5g04o69k6rf4wcf\n7rQfevBeMz6bAeOjIlMqo9XctMgQu+eeu5WsuMSccEtHv8ffWZ1V/ZqCQ71a17p+KRKcc8P6Hkh3\n4fwMc91ljOp5YA+r9w2je5JQNyPBK2c1wKZwPTUst2CQUXesRttsMRl1Z92FkqhEqsMJnrIud56M\noJMRebafxOiINmnuvpPv1fmLfE8XF7UbV3HpWZ6P2LNpyFlZl2OtxvdOuv0AgAL/7mOCjzZtCFIk\nF+XomH72m7WWql/sSk/cGP7GdzgGEL7wHY4BRH8599IpTE61uN8mp7WqIneZm42fUrItW1g9nhhn\nEop83nBmC9Xwu9/9nhKlBGmbJEWoVDTZRllQdqcNMcSRo+xFGGnyuYdy+loqgr+tYtS60hKPv3D6\nspItLvJOraSTtoks8pBMSaqMUPWlFWATT6Rqbnfda2KXXNI9WxVVqvM2GUlGwkkqcrubLvtZ6moV\nrSfLi0Ejm+HH2ObXyF39FUm+YVXi+Mppibq+FDUSyEJCAh17LQgyD1ECrJDTJ06n+Jlrmqi+8XZJ\ntIUlndgTB3/jOxwDCF/4DscAwhe+wzGA6LONn8a2rVMAgGpNR3o9+tCDnXYnCqmNr33tuU77iccf\n77RzJotPkmOOGxJKSYCxJOwgW1ZYuo1ef+0VJfvD//8PO+1//s+e7rRLdT3ftSKPv7Cgba7lJXYj\n2QwxaQtL11nKlFLKCSKHkOACkxly1u3XEHa9jTKrxdj13ZzyMuuuN1dc1EVkIUqWGWNaEppo95ju\ntyrs4lNnzb7JEhNuBB0naOaBeCTI9J6CzPCzQ4gISBPIWJYRkIJMtl7X5KbDOe6XzeoSdLW2jU9d\nRR42Rk8Ln4hOA1hBq7x9PYTwBBFNAvhjAPsBnAbw8RDCQtwYDofj7YNrUfV/NoRwMISwHlD+GQDP\nhRDuAfBc+9jhcPwY4EZU/Y8CeKrd/jxaNfU+nfSFSqmMtw6/BQDYeWCvkjUET3jF8NlvnWZ3Xq3G\n6s/cnOXEY7U9axJPSiX+njQJbISVjFq7eFHzzY8McyTV6TOnO+1cQyddLAtTomGSV7TKbdRe4WLK\nZIWam9I/U1Xw1lkVXh5Kdb6b+08mnlg33cbqvXX7RYpb0LriZJs2/BzYJGJORhBKU83w5Z0+x+r9\n6qp+dtSQyjSx55KT1zISBCTByuRx/KUg6R0rf0P5vFTMKGVhlg6ltYk6PLT+vPcWZ9jrGz8A+Asi\neomI1o3b7SGEdfbCywC2b/xVh8PxdkOvb/wnQwgXiGgbgK8T0ZtSGEIIRF1R2ACA9h+KpwFg546d\nG3VxOBx9Rk9v/BDChfb/MwC+hFZ57CtEtBMA2v/PxHz3mRDCEyGEJ7aYiq0Oh+P2YNM3PhENA4hC\nCCvt9ocA/D8AngXwCQC/2f7/y5uNtbK4jG9/5asAgA/9448pmbTnMsZNt2cv7wesijpjlvdeuYaM\nLZYRLrG6sJFtfTxpn68Wte1+8LHHuN8iOzDSDe12SbKf5XHduhJTos6bGMNWlGuKv9c2jFaNr8p6\na/tc8t4H6+prbGwnRpF12cmQ3a6idRuOYW1reerIfEfuUczNc2lpGYYLAJUqPweWV1/NN2F+TeFu\n647Y7TE/LyELUd6eLt7+mHtlu1VEnYSKIUUptkPPawl1CiR6UfW3A/hSe1GlAfzXEMJXiegHAL5I\nRJ8EcAbAx3s6o8PhuO3YdOGHEE4CeHSDz+cAfOBWTMrhcNxa9DVyL6CJRrNVhmpxQXOG7d7JToHD\nhw8r2YlTzH13z71cMrpQ0EQFUoVfMllKK6J8dF2ohsWiJmQ4dZJLVa8sa1X/sccf6bRPH+P9zWbN\nRrRxm0wWVVryyBuZUu+jeHMhKWJORv9Jsg3LNy9VfcmP3z4DzzfNj4gNCpOeSuu2lBx8JWFOpdM6\nCjGTlo+gvs4FEeV4ZVZmLpry0eqAYmU6SlAjCvGuSRkd2SWTpbdiJ6U/6BLJMSihn5yH0eg7z45z\n7jkcjjj4wnc4BhC+8B2OAURfbfz8yDDuf1+Lt75qmG9efIEZc37jX/+GkpFgtPnUr/16pz29VTPf\nVIXtvrK8rGTzc1w3rbzGLsFUpI2lkyfYdl9e0m66CGzjR01hZxpbXdv48dloXbXipCtOklXakFox\n5aYNCRYuH+WySwiHtR4wWwq6M7bZJ5DzlzXw7JipYVkW2jDwRPEMPBMTzLY0PsbEpDJ8FzAsPgmu\nsqTENfm1uskcbULut+jvyTBmuc/RFaotiUnNnoquQdiI7SfHtHUM1klRk4hIJfyN73AMIHzhOxwD\niD6XyU5heHQMAJAyRJbf+s53Ou3xCR3ae+ECu/OOvnmk065W96t+c3Mc0bW6olX9/BATF2REhNzs\nJZ2Bd+YEu/OQ0mQHV2evdNpSLY3MtUjCh67sOZUxF0+OIRPhLGe9LE/VsOWpY1xsNrNOHtqIPDUn\npVImlbHW38sIAswm4iPaYlI8AAC5LGdYJrnsJGzJcmlqSWKPsqkRIKMXq6a0ubw/1h2ZG+JjWTqt\nW+WWkZJxEvMMdGV2xj8765GT3/nOHHqBv/EdjgGEL3yHYwDR32q5xDurFy6cV6L5OU56Ofj4Y0om\nOeHOnj7ZaTcbFdVPlk8q5DURx5lTpzrtY8JcqBnvQkbsTs/M62SQ48fe6rS3CH7/VMqodUI1tOWp\n5HG3+r0xIYPlxJNVa63KJ8doJnDnSwTLAd+UO/4JJBqSVy/JeyETcRLMCjuGvK+R8pzEmwfNpja7\npCkhv5XLmqhJYT5FkV0W0nthJTJRSZ434Tq7PCDClBDnCkGfTJuJdh7Unntv73J/4zscAwhf+A7H\nAMIXvsMxgOirjV+r1XDpUoum7/jxY1oo7JmDj71TiapVtuXHx7ic9ogpM31KjPn6668p2ZUr7IqT\nLrBCIa/6DYuMv+3bp5Usm2XXTVNFi6luaNbj3W0qm6vLPpfc6/ERXCEhIk/Xs4s/l7QFbeaeRFKk\nobTXrW2pefU3Hg/QmYfW9k0J91jPtqtxn8aRaESRvR+C6DRjryWGUbMl7DSbKqIwfr7WhRm3H9A0\n1yKJZ2x9gvV9iO7IxY3hb3yHYwDhC9/hGED0VdWvVqs4f/YcAOCM4KUHgIktU532tq3blGznrl2d\n9pHXWIV/6+hR1W9OJOJMT44r2SMP3t1p54a43HChoEttZYUsSukoLfl3UkXnmQirkOiy2zipo1u2\nMaGG7ZdIDJHgbutVJUyCVFHtdYYY4gkK8Yk+Vo2WYyqTw/LlhXi3ZZKpIqHdjPHlwBK5BSnetIob\nL2mONsKvVuUPslk9j1yu9awmcQ5K+Bvf4RhA+MJ3OAYQvvAdjgFEX238eq2Gy5db7rzzZ3XI7vjY\n1k67XNahuJUKuzG+//3vd9pcL6yFgw/f02lv26pdcdJeV7Z7ZGMwxXEXJ75oNzd2m7Vk8TZnUsZc\nnKxh7WdJxJFQz04SajQNeYW0JZNcZUl2ceI+QZD2uXTLxWf42fp+zWacfW5sfHNtevx4okw13QQC\nU32vksqSxxfgk5mBlixU723E72Vksrxc7ZWsrxFLzBoHf+M7HAMIX/gOxwCir6r+4sIivvylPwMA\nrBg++5/+mQ922uWyKUklSmg/cM++TnvnNq3OZ7Lsimvav2mRVO/FZVN8plRX+asY9b6LUCORey3e\nRFBloRvSZRdPopGEoNRtLbseVT9JBU6KDFTfs/MQp7bziGLO3T0PNs+S1PlezZYkd1uvbtCu36zL\nDbhxX1IuYw05go3qg80Q3QQ9vfGJaIKI/gcRvUlER4jovUQ0SURfJ6Jj7f+9IqbD8WOCXlX93wXw\n1RDC/WiV0zoC4DMAngsh3APgufaxw+H4MUAv1XLHAfw0gH8CACGEKoAqEX0UwFPtbp8H8E0An04a\nq1Kt4HSbSCOd0TvyJ04c77QfuHC/ki0JQoz9onJusIkKQuVLWWIIeZygNiZF1sVF5HWVjxK7tklj\nWKhdfRm510XSFq+mJxFuSCQRYkgkq8fx/eS8lNofJUSt2TlKUgr1uZmH9F7AeEBi7neSOp/Ut1f6\n6u4xkswu6X2Jr2IsH3dLZ36tkZi9vPHvBDAL4D8T0ctE9PvtctnbQwiX2n0uo1VV1+Fw/Bigl4Wf\nBvA4gN8LITwGYBVGrQ+tPzcb/skhoqeJ6BARHboZ8eEOh+PG0cvCPw/gfAjhhfbx/0DrD8EVItoJ\nAO3/Zzb6cgjhmRDCEyGEJ65XTXI4HDcXm9r4IYTLRHSOiO4LIRwF8AEAb7T/fQLAb7b///JmY0VR\nhEKh5XKrG/KHSxfPddrfev55JZsY4WlKQk0bdRelenPTSc2jbqKokjLfZF9pdtcbmoddkWF2ZZwl\ncd3L46RMMm4HWJu+tz+uvWpfzRjiTXvuFMXbnPK6UnYvIMFV1hTZbhSkvR9PttFt/29M/p9Ugtoi\nydUXh657FTZutz/ZeBo9lvzWI/SGXv34/yeAPyKiLICTAP4pWvf4i0T0SQBnAHz8Gs/tcDhuE3pa\n+CGEVwA8sYHoAzd3Og6Hox/oa+QeEZBuE5PbyKN6jfntaxUd1VfYtqfT1gk21p0Xv2UR5367tiSa\njckxrLtNHndH3QmZdb0p9xi3U4bMXZ0voTpsryQUSWopFM+7/l6vLkE1tlFKJbegJZHQfP/SdLBj\nirYl4hBur0RV+TrU+SR0R2XGy+R91LL4MbqV+5vvznM4HP+bwRe+wzGA8IXvcAwg+mrjZ9JpbN/e\nItyYmNBkmNNTnGk3NjaqZKm0DO8VGWw2QwnxmW/SFadsd0uTLsdPzKwT3wk2TDSeiENGrNqadTqU\nWHwM0018UjcXoLLdKMk+3ziEeX1mG7W7rchrz1oj866RR2RdsDF7CF33VF5ngu3ey+ebyZLmkhTa\nK+14e51x57bhx4ghMAW6iTk3g7/xHY4BhC98h2MAQf2MnyeiWbSCfaYBXN2k+63G22EOgM/Dwueh\nca3z2BdC2LpZp74u/M5JWwk7GwUEDdQcfB4+j9s1D1f1HY4BhC98h2MAcbsW/jO36bwSb4c5AD4P\nC5+Hxi2Zx22x8R0Ox+2Fq/oOxwCirwufiD5MREeJ6DgR9Y2Vl4j+gIhmiOh18Vnf6cGJaC8RfYOI\n3iCiHxHRp27HXIhoiIheJKJX2/P4t+3P7ySiF9q/zx+3+RduOYgo1eZz/MrtmgcRnSai14joFSI6\n1P7sdjwjfaGy79vCp1bVg/8I4OcBPAjgl4nowT6d/r8A+LD57HbQg9cB/FoI4UEA7wHwq+170O+5\nVAC8P4TwKICDAD5MRO8B8FsAfieEcDeABQCfvMXzWMen0KJsX8ftmsfPhhAOCvfZ7XhG+kNlH0Lo\nyz8A7wXwNXH8WQCf7eP59wN4XRwfBbCz3d4J4Gi/5iLm8GUAH7ydcwFQAPBDAO9GK1AkvdHvdQvP\nv6f9ML8fwFfQCkO/HfM4DWDafNbX3wXAOIBTaO+93cp59FPV3w3gnDg+3/7sduG20oMT0X4AjwF4\n4XbMpa1ev4IWSerXAZwAsBhCWM9m6tfv8x8A/DrQyUiZuk3zCAD+goheIqKn25/1+3fpG5W9b+4h\nmR78VoCIRgD8CYB/GUJYvh1zCSE0QggH0XrjvgvA/Zt85aaDiH4BwEwI4aV+n3sDPBlCeBwtU/RX\nieinpbBPv8sNUdlfC/q58C8A2CuO97Q/u13oiR78ZoOIMmgt+j8KIfzp7ZwLAIQQFgF8Ay2VeoKI\n1lO1+/H7vA/A3yKi0wC+gJa6/7u3YR4IIVxo/z8D4Eto/THs9+9yQ1T214J+LvwfALinvWObBfBL\nAJ7t4/ktnkWLFhzokR78RkGtJO3PATgSQvjt2zUXItpKRBPtdh6tfYYjaP0B+Fi/5hFC+GwIYU8I\nYT9az8PzIYR/2O95ENP6xlgAAADMSURBVNEwEY2utwF8CMDr6PPvEkK4DOAcEd3X/midyv7mz+NW\nb5qYTYqPAHgLLXvyN/p43v8G4BKAGlp/VT+Jli35HIBjAP4SwGQf5vEkWmraYQCvtP99pN9zAfAI\ngJfb83gdwP/d/vwAgBcBHAfw3wHk+vgbPQXgK7djHu3zvdr+96P1Z/M2PSMHARxq/zZ/BmDLrZiH\nR+45HAMI39xzOAYQvvAdjgGEL3yHYwDhC9/hGED4wnc4BhC+8B2OAYQvfIdjAOEL3+EYQPwvQ0Tm\n7fuF0moAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa0d93ea9e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "index = 1 \n",
    "plt.imshow(train_set_x_orig[index])\n",
    "print (\"y = \" + str(train_set_y[0, index]) + \", it's a '\" + classes[train_set_y[0, index]].decode(\"utf-8\") +  \"' picture.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Exercise ###\n",
    "\n",
    "**Bài tập**: tính toán các giá trị sau:\n",
    "- `m_train`: số lượng mẫu của tập train\n",
    "- `m_test`: số lượng mẫu của tập test\n",
    "- `num_px`: số lượng pixel theo mỗi chiều (= height = width của 1 bức ảnh) \n",
    "\n",
    "**Gợi ý**: `train_set_x_orig` là một numpy-array có chiều là `(m_train, num_px, num_px, 3)`. Ví dụ, có thể lấy giá trị `m_train` bằng lệnh `train_set_x_orig.shape[0]`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: m_train = None\n",
      "Number of testing examples: m_test = None\n",
      "Height/Width of each image: num_px = None\n",
      "Each image is of size: (None, None, 3)\n",
      "train_set_x shape: (209, 64, 64, 3)\n",
      "train_set_y shape: (1, 209)\n",
      "test_set_x shape: (50, 64, 64, 3)\n",
      "test_set_y shape: (1, 50)\n"
     ]
    }
   ],
   "source": [
    "### START CODE HERE ###\n",
    "m_train = None\n",
    "m_test = None\n",
    "num_px = None\n",
    "### END CODE HERE ###\n",
    "\n",
    "print (\"Number of training examples: m_train = \" + str(m_train))\n",
    "print (\"Number of testing examples: m_test = \" + str(m_test))\n",
    "print (\"Height/Width of each image: num_px = \" + str(num_px))\n",
    "print (\"Each image is of size: (\" + str(num_px) + \", \" + str(num_px) + \", 3)\")\n",
    "print (\"train_set_x shape: \" + str(train_set_x_orig.shape))\n",
    "print (\"train_set_y shape: \" + str(train_set_y.shape))\n",
    "print (\"test_set_x shape: \" + str(test_set_x_orig.shape))\n",
    "print (\"test_set_y shape: \" + str(test_set_y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output for m_train, m_test and num_px**: \n",
    "- Number of training examples: m_train = 209\n",
    "- Number of testing examples: m_test = 50\n",
    "- Height/Width of each image: num_px = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Kiến trúc Logistic Regression\n",
    "\n",
    "<img src=\"images/LogReg_kiank.png\" style=\"width:650px;height:400px;\">\n",
    "\n",
    "**Các công thức sử dụng trong thuật toán**:\n",
    "\n",
    "Với mỗi ví dụ $x^{(i)}$:\n",
    "- Tính giá trị $z$:\n",
    "$$z^{(i)} = w^T x^{(i)} + b$$\n",
    "- Tính giá trị dự đoán $\\hat{y}$ với hàm kích hoạt `sigmoid`:\n",
    "$$\\hat{y}^{(i)} = a^{(i)} = sigmoid(z^{(i)})$$ \n",
    "- Tính hàm mất mát theo công thức:\n",
    "$$ \\mathcal{L}(a^{(i)}, y^{(i)}) =  - y^{(i)}  \\log(a^{(i)}) - (1-y^{(i)} )  \\log(1-a^{(i)})$$\n",
    "\n",
    "- Hàm giá trị được tính bằng tổng các giá trị mất mát trên toàn bộ ví dụ:\n",
    "$$ J = \\frac{1}{m} \\sum_{i=1}^m \\mathcal{L}(a^{(i)}, y^{(i)})$$\n",
    "\n",
    "**Các bước quan trọng**:\n",
    "Trong bài tập này, thực hiện tuần tự các yêu cầu sau: \n",
    "- Khởi tạo các giá trị $W,b$ của mô hình \n",
    "- Thực hiện tối ưu hàm chi phí $J$ để tìm bộ tham số của mô hình  \n",
    "- Sử dụng bộ tham số vừa học, thực hiện dự đoán trên tập dữ liệu test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bài tập**: Thay đổi chiều dữ liệu. Mỗi bức ảnh có chiều `(num_px, num_px, 3)`, chuyển về vector có dạng `(num_px ∗ num_px ∗ 3, 1)`.\n",
    "\n",
    "**Gợi ý**: một ma trận 4-D `X` có chiều `(a,b,c,d)`, đổi chiều thành ma trận 2-D `X_flatten` có chiều `(b*c*d,a)` bằng cách sử dụng hàm `reshape()` \n",
    "- Cách 1:\n",
    "```python\n",
    "X_flatten = X.reshape(b*c*d, a)\n",
    "```\n",
    "- Cách 2:\n",
    "```python\n",
    "X_flatten = X.reshape(a, -1).T # X.T là ma trận chuyển vị của X\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-951b995592e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m### END CODE HERE ###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"train_set_x_flatten shape: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_set_x_flatten\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"train_set_y shape: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_set_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"test_set_x_flatten shape: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_set_x_flatten\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "# Reshape the training and test examples\n",
    "\n",
    "### START CODE HERE ###\n",
    "train_set_x_flatten = None\n",
    "test_set_x_flatten = None\n",
    "### END CODE HERE ###\n",
    "\n",
    "print (\"train_set_x_flatten shape: \" + str(train_set_x_flatten.shape))\n",
    "print (\"train_set_y shape: \" + str(train_set_y.shape))\n",
    "print (\"test_set_x_flatten shape: \" + str(test_set_x_flatten.shape))\n",
    "print (\"test_set_y shape: \" + str(test_set_y.shape))\n",
    "print (\"sanity check after reshaping: \" + str(train_set_x_flatten[0:5,0]))\n",
    "\n",
    "# standardize dataset\n",
    "train_set_x = train_set_x_flatten/255.\n",
    "test_set_x = test_set_x_flatten/255."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**: \n",
    "\n",
    "<table style=\"width:35%\">\n",
    "  <tr>\n",
    "    <td>**train_set_x_flatten shape**</td>\n",
    "    <td> (12288, 209)</td> \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>**train_set_y shape**</td>\n",
    "    <td>(1, 209)</td> \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>**test_set_x_flatten shape**</td>\n",
    "    <td>(12288, 50)</td> \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>**test_set_y shape**</td>\n",
    "    <td>(1, 50)</td> \n",
    "  </tr>\n",
    "  <tr>\n",
    "  <td>**sanity check after reshaping**</td>\n",
    "  <td>[17 31 56 22 33]</td> \n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - Xây dựng mô hình Logistic Regression\n",
    "\n",
    "Các bước chính để xây dựng một mô hình:\n",
    "1. Định nghĩa cấu trúc mô hình (số chiều của input, hàm kích hoạt, ...)\n",
    "2. Khởi tạo các tham số của mô hình\n",
    "3. Lặp:\n",
    "    - Tính giá trị hàm chi phí $J$ (forward propagation - lan truyền xuôi)\n",
    "    - Tính giá trị đạo hàm (backward propagation - lan truyền ngược)\n",
    "    - Cập nhật tham số (gradient descent)\n",
    "    \n",
    "Tổng hợp cả 3 bước trên tạo thành một hàm, được gọi là `model()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. Hàm kích hoạt ###\n",
    "**Bài tập**: Xây dựng hàm `sigmoid()`, sử dụng np.exp()\n",
    "\n",
    "**Gợi ý**: \n",
    "- Hàm sigmoid có công thức là:\n",
    "$$sigmoid(x) = \\frac{1}{1+e^{-x}}$$\n",
    "- Trong trường hợp $x$ là một vector, `sigmoid(x)` sẽ được tính như sau:\n",
    "$$ \\text{For } x \\in \\mathbb{R}^n \\text{,     } sigmoid(x) = sigmoid\\begin{pmatrix}\n",
    "    x_1  \\\\\n",
    "    x_2  \\\\\n",
    "    ...  \\\\\n",
    "    x_n  \\\\\n",
    "\\end{pmatrix} = \\begin{pmatrix}\n",
    "    \\frac{1}{1+e^{-x_1}}  \\\\\n",
    "    \\frac{1}{1+e^{-x_2}}  \\\\\n",
    "    ...  \\\\\n",
    "    \\frac{1}{1+e^{-x_n}}  \\\\\n",
    "\\end{pmatrix} $$\n",
    "- Đồ thị hàm sigmoid\n",
    "\n",
    "<img src=\"images/sigmoid.png\" style=\"width:500px;height:228px;\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: sigmoid\n",
    "def sigmoid(z):\n",
    "    \"\"\"\n",
    "    Compute the sigmoid of z\n",
    "\n",
    "    Arguments:\n",
    "    z -- A scalar or numpy array of any size.\n",
    "\n",
    "    Return:\n",
    "    s -- sigmoid(z)\n",
    "    \"\"\"\n",
    "\n",
    "    ### START CODE HERE ###\n",
    "    s = None\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigmoid([0, 2]) = None\n"
     ]
    }
   ],
   "source": [
    "print (\"sigmoid([0, 2]) = \" + str(sigmoid(np.array([0,2]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**: sigmoid([0, 2]) = [0.5        0.88079708]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 - Khởi tạo tham số\n",
    "\n",
    "**Bài tập**: Khởi tạo $W$ là vector toàn giá trị 0, $b$ là số thực có giá trị bằng 0\n",
    "\n",
    "**Gợi ý**: Sử dụng hàm `np.zeros()` trong như viện `numpy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: initialize_with_zeros\n",
    "\n",
    "def initialize_with_zeros(dim):\n",
    "    \"\"\"\n",
    "    This function creates a vector of zeros of shape (dim, 1) for w and initializes b to 0.\n",
    "    \n",
    "    Argument:\n",
    "    dim -- size of the w vector we want (or number of parameters in this case)\n",
    "    \n",
    "    Returns:\n",
    "    w -- initialized vector of shape (dim, 1)\n",
    "    b -- initialized scalar (corresponds to the bias)\n",
    "    \"\"\"\n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    w = None\n",
    "    b = None\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    assert(w.shape == (dim, 1))\n",
    "    assert(isinstance(b, float) or isinstance(b, int))\n",
    "    \n",
    "    return w, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 2\n",
    "w, b = initialize_with_zeros(dim)\n",
    "print (\"w = \" + str(w))\n",
    "print (\"b = \" + str(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**: \n",
    "\n",
    "\n",
    "<table style=\"width:15%\">\n",
    "    <tr>\n",
    "        <td>  ** w **  </td>\n",
    "        <td> [[ 0.]\n",
    " [ 0.]] </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>  ** b **  </td>\n",
    "        <td> 0 </td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "**Lưu ý**: Với đầu vào là ảnh , $W$ có chiều là (num_px $\\times$ num_px $\\times$ 3, 1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 - Lan truyền xuôi - ngược\n",
    "\n",
    "**Bài tập:** Xây dựng hàm `propagate()` tính toán hàm chi phí và and giá trị đạo hàm của nó.\n",
    "\n",
    "**Gợi ý**:\n",
    "\n",
    "1. Forward Propagation:\n",
    "    - Đầu vào X\n",
    "    - Tính giá trị $A = (a^{(1)}, a^{(2)}, ..., a^{(m-1)}, a^{(m)}) = \\sigma(w^T X + b) $\n",
    "    - Tính giá trị hàm chi phí: $J = -\\frac{1}{m}\\sum_{i=1}^{m}y^{(i)}\\log(a^{(i)})+(1-y^{(i)})\\log(1-a^{(i)})$\n",
    "\n",
    "2. Backward Propagation:\n",
    "\n",
    "$$ dw = \\frac{\\partial J}{\\partial w} = \\frac{1}{m}X(A-Y)^T$$\n",
    "$$ db = \\frac{\\partial J}{\\partial b} = \\frac{1}{m} \\sum_{i=1}^m (a^{(i)}-y^{(i)})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: propagate\n",
    "\n",
    "def propagate(w, b, X, Y):\n",
    "    \"\"\"\n",
    "    Implement the cost function and its gradient for the propagation explained above\n",
    "\n",
    "    Arguments:\n",
    "    w -- weights, a numpy array of size (num_px * num_px * 3, 1)\n",
    "    b -- bias, a scalar\n",
    "    X -- data of size (num_px * num_px * 3, number of examples)\n",
    "    Y -- true \"label\" vector (containing 0 if non-cat, 1 if cat) of size (1, number of examples)\n",
    "\n",
    "    Return:\n",
    "    cost -- negative log-likelihood cost for logistic regression\n",
    "    dw -- gradient of the loss with respect to w, thus same shape as w\n",
    "    db -- gradient of the loss with respect to b, thus same shape as b\n",
    "    \n",
    "    Tips:\n",
    "    - Write your code step by step for the propagation\n",
    "    \"\"\"\n",
    "    \n",
    "    m = X.shape[1]\n",
    "    \n",
    "    # FORWARD PROPAGATION (FROM X TO COST)\n",
    "    ### START CODE HERE ###\n",
    "    A = None\n",
    "    cost = None\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # BACKWARD PROPAGATION (TO FIND GRAD)\n",
    "    ### START CODE HERE ###\n",
    "    dw = None\n",
    "    db = None\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    assert(dw.shape == w.shape)\n",
    "    assert(db.dtype == float)\n",
    "    cost = np.squeeze(cost)\n",
    "    assert(cost.shape == ())\n",
    "    \n",
    "    grads = {\"dw\": dw,\n",
    "             \"db\": db}\n",
    "    \n",
    "    return grads, cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w, b, X, Y = np.array([[1.],[2.]]), 2., np.array([[1.,2.,-1.],[3.,4.,-3.2]]), np.array([[1,0,1]])\n",
    "grads, cost = propagate(w, b, X, Y)\n",
    "print (\"dw = \" + str(grads[\"dw\"]))\n",
    "print (\"db = \" + str(grads[\"db\"]))\n",
    "print (\"cost = \" + str(cost))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**:\n",
    "\n",
    "<table style=\"width:50%\">\n",
    "    <tr>\n",
    "        <td>  ** dw **  </td>\n",
    "      <td> [[ 0.99845601]\n",
    "     [ 2.39507239]]</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>  ** db **  </td>\n",
    "        <td> 0.00145557813678 </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>  ** cost **  </td>\n",
    "        <td> 5.801545319394553 </td>\n",
    "    </tr>\n",
    "\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 - Tối ưu hàm chi phí\n",
    "**Bài tập:** Xây dựng hàm `optimize()` thực hiện quá trình tối ưu mô hình. \n",
    "\n",
    "**Gợi ý**: \n",
    "1. Mục tiêu là tìm ra bộ tham số $w$ và $b$ bằng các tối ưu hàm chi phí $J$. \n",
    "2. Với tham số $\\theta$, quy luật cập nhật tham số là $ \\theta = \\theta - \\alpha \\times d\\theta$, trong đó $\\alpha$ giá trị tỉ lệ học (learning rate)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: optimize\n",
    "\n",
    "def optimize(w, b, X, Y, num_iterations, learning_rate, print_cost = False):\n",
    "    \"\"\"\n",
    "    This function optimizes w and b by running a gradient descent algorithm\n",
    "    \n",
    "    Arguments:\n",
    "    w -- weights, a numpy array of size (num_px * num_px * 3, 1)\n",
    "    b -- bias, a scalar\n",
    "    X -- data of shape (num_px * num_px * 3, number of examples)\n",
    "    Y -- true \"label\" vector (containing 0 if non-cat, 1 if cat), of shape (1, number of examples)\n",
    "    num_iterations -- number of iterations of the optimization loop\n",
    "    learning_rate -- learning rate of the gradient descent update rule\n",
    "    print_cost -- True to print the loss every 100 steps\n",
    "    \n",
    "    Returns:\n",
    "    params -- dictionary containing the weights w and bias b\n",
    "    grads -- dictionary containing the gradients of the weights and bias with respect to the cost function\n",
    "    costs -- list of all the costs computed during the optimization, this will be used to plot the learning curve.\n",
    "    \n",
    "    Tips:\n",
    "    You basically need to write down two steps and iterate through them:\n",
    "        1) Calculate the cost and the gradient for the current parameters. Use propagate().\n",
    "        2) Update the parameters using gradient descent rule for w and b.\n",
    "    \"\"\"\n",
    "    \n",
    "    costs = []\n",
    "    \n",
    "    for i in range(num_iterations):\n",
    "        \n",
    "        \n",
    "        # Cost and gradient calculation\n",
    "        ### START CODE HERE ### \n",
    "        grads, cost = None\n",
    "        ### END CODE HERE ###\n",
    "        \n",
    "        # Retrieve derivatives from grads\n",
    "        dw = grads[\"dw\"]\n",
    "        db = grads[\"db\"]\n",
    "        \n",
    "        # update rule\n",
    "        ### START CODE HERE ###\n",
    "        w = None\n",
    "        b = None\n",
    "        ### END CODE HERE ###\n",
    "        \n",
    "        # Record the costs\n",
    "        if i % 100 == 0:\n",
    "            costs.append(cost)\n",
    "        \n",
    "        # Print the cost every 100 training examples\n",
    "        if print_cost and i % 100 == 0:\n",
    "            print (\"Cost after iteration %i: %f\" % (i, cost))\n",
    "    \n",
    "    params = {\"w\": w,\n",
    "              \"b\": b}\n",
    "    \n",
    "    grads = {\"dw\": dw,\n",
    "             \"db\": db}\n",
    "    \n",
    "    return params, grads, costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params, grads, costs = optimize(w, b, X, Y, num_iterations= 100, learning_rate = 0.009, print_cost = False)\n",
    "\n",
    "print (\"w = \" + str(params[\"w\"]))\n",
    "print (\"b = \" + str(params[\"b\"]))\n",
    "print (\"dw = \" + str(grads[\"dw\"]))\n",
    "print (\"db = \" + str(grads[\"db\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**: \n",
    "\n",
    "<table style=\"width:40%\">\n",
    "    <tr>\n",
    "       <td> **w** </td>\n",
    "       <td>[[ 0.19033591]\n",
    " [ 0.12259159]] </td>\n",
    "    </tr>\n",
    "    \n",
    "    <tr>\n",
    "       <td> **b** </td>\n",
    "       <td> 1.92535983008 </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "       <td> **dw** </td>\n",
    "       <td> [[ 0.67752042]\n",
    " [ 1.41625495]] </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "       <td> **db** </td>\n",
    "       <td> 0.219194504541 </td>\n",
    "    </tr>\n",
    "\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 - Hàm dự đoán\n",
    "**Bài tập:** Xây dựng hàm thực hiện dự đoán, sử dụng $w$ và $b$ đã học được. \n",
    "\n",
    "**Gợi ý**: Có 2 bước để thực hiện dự đoán với một đầu vào mới\n",
    "1. Tính $\\hat{Y} = A = \\sigma(w^T X + b)$\n",
    "2. Với mỗi ví dụ, thực hiện chuyển đổi giá trị dự đoán thành 0 (nếu activation <= 0.5) hoặc 1 (nếu activation > 0.5). Lưu giá trị dự đoán của mỗi ví dụ vào một vector `Y_prediction`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: predict\n",
    "\n",
    "def predict(w, b, X):\n",
    "    '''\n",
    "    Predict whether the label is 0 or 1 using learned logistic regression parameters (w, b)\n",
    "    \n",
    "    Arguments:\n",
    "    w -- weights, a numpy array of size (num_px * num_px * 3, 1)\n",
    "    b -- bias, a scalar\n",
    "    X -- data of size (num_px * num_px * 3, number of examples)\n",
    "    \n",
    "    Returns:\n",
    "    Y_prediction -- a numpy array (vector) containing all predictions (0/1) for the examples in X\n",
    "    '''\n",
    "    \n",
    "    m = X.shape[1]\n",
    "    Y_prediction = np.zeros((1,m))\n",
    "    w = w.reshape(X.shape[0], 1)\n",
    "    \n",
    "    # Compute vector \"A\" predicting the probabilities of a cat being present in the picture\n",
    "    ### START CODE HERE ###\n",
    "    A = None\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    for i in range(A.shape[1]):\n",
    "        \n",
    "        # Convert probabilities A[0,i] to actual predictions p[0,i]\n",
    "        ### START CODE HERE ###\n",
    "        pass\n",
    "        ### END CODE HERE ###\n",
    "    \n",
    "    assert(Y_prediction.shape == (1, m))\n",
    "    \n",
    "    return Y_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = np.array([[0.1124579],[0.23106775]])\n",
    "b = -0.3\n",
    "X = np.array([[1.,-1.1,-3.2],[1.2,2.,0.1]])\n",
    "print (\"predictions = \" + str(predict(w, b, X)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**: predictions = [[1. 1. 0.]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 - Model ##\n",
    "\n",
    "**Bài tập:** Xây dựng hàm `model()`. Sử dụng những biến sau:\n",
    "    - Y_prediction_test: dự đoán trên tập test\n",
    "    - Y_prediction_train: dự đoán trên tập train\n",
    "    - w, costs, grads: đầu ra của hàm optimize()\n",
    "    \n",
    "**Gợi ý**: Tổng hợp của tất cả các hàm đã xây dựng ở trên theo đúng thứ tự."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: model\n",
    "\n",
    "def model(X_train, Y_train, X_test, Y_test, num_iterations = 2000, learning_rate = 0.5, print_cost = False):\n",
    "    \"\"\"\n",
    "    Builds the logistic regression model by calling the function you've implemented previously\n",
    "    \n",
    "    Arguments:\n",
    "    X_train -- training set represented by a numpy array of shape (num_px * num_px * 3, m_train)\n",
    "    Y_train -- training labels represented by a numpy array (vector) of shape (1, m_train)\n",
    "    X_test -- test set represented by a numpy array of shape (num_px * num_px * 3, m_test)\n",
    "    Y_test -- test labels represented by a numpy array (vector) of shape (1, m_test)\n",
    "    num_iterations -- hyperparameter representing the number of iterations to optimize the parameters\n",
    "    learning_rate -- hyperparameter representing the learning rate used in the update rule of optimize()\n",
    "    print_cost -- Set to true to print the cost every 100 iterations\n",
    "    \n",
    "    Returns:\n",
    "    d -- dictionary containing information about the model.\n",
    "    \"\"\"\n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    \n",
    "    # initialize parameters with zeros\n",
    "    w, b = None\n",
    "\n",
    "    # Gradient descent\n",
    "    parameters, grads, costs = None\n",
    "    \n",
    "    # Retrieve parameters w and b from dictionary \"parameters\"\n",
    "    w = parameters[\"w\"]\n",
    "    b = parameters[\"b\"]\n",
    "    \n",
    "    # Predict test/train set examples\n",
    "    Y_prediction_test = None\n",
    "    Y_prediction_train = None\n",
    "\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    # Print train/test Errors\n",
    "    print(\"train accuracy: {} %\".format(100 - np.mean(np.abs(Y_prediction_train - Y_train)) * 100))\n",
    "    print(\"test accuracy: {} %\".format(100 - np.mean(np.abs(Y_prediction_test - Y_test)) * 100))\n",
    "\n",
    "    \n",
    "    d = {\"costs\": costs,\n",
    "         \"Y_prediction_test\": Y_prediction_test, \n",
    "         \"Y_prediction_train\" : Y_prediction_train, \n",
    "         \"w\" : w, \n",
    "         \"b\" : b,\n",
    "         \"learning_rate\" : learning_rate,\n",
    "         \"num_iterations\": num_iterations}\n",
    "    \n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = model(train_set_x, train_set_y, test_set_x, test_set_y, num_iterations = 2000, learning_rate = 0.005, print_cost = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**: \n",
    "\n",
    "<table style=\"width:40%\"> \n",
    "\n",
    "    <tr>\n",
    "        <td> **Cost after iteration 0 **  </td> \n",
    "        <td> 0.693147 </td>\n",
    "    </tr>\n",
    "      <tr>\n",
    "        <td> <center> $\\vdots$ </center> </td> \n",
    "        <td> <center> $\\vdots$ </center> </td> \n",
    "    </tr>  \n",
    "    <tr>\n",
    "        <td> **Train Accuracy**  </td> \n",
    "        <td> 99.04306220095694 % </td>\n",
    "    </tr>\n",
    "\n",
    "    <tr>\n",
    "        <td>**Test Accuracy** </td> \n",
    "        <td> 70.0 % </td>\n",
    "    </tr>\n",
    "</table> \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot learning curve (with costs)\n",
    "costs = np.squeeze(d['costs'])\n",
    "plt.plot(costs)\n",
    "plt.ylabel('cost')\n",
    "plt.xlabel('iterations (per hundreds)')\n",
    "plt.title(\"Learning rate =\" + str(d[\"learning_rate\"]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 - Dự đoán ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of a picture that was wrongly classified.\n",
    "index = 1\n",
    "plt.imshow(test_set_x[:,index].reshape((num_px, num_px, 3)))\n",
    "print (\"y = \" + str(test_set_y[0,index]) + \", you predicted that it is a \\\"\" + classes[int(d[\"Y_prediction_test\"][0,index])].decode(\"utf-8\") +  \"\\\" picture.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
